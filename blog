#!/usr/bin/env python
import base64
import datetime
import glob
import hashlib
import io
import json
import os
import re
import shutil
import signal
import socket
import subprocess
import sys
import tempfile
import time
import webbrowser
from collections import Counter
from os.path import *
from typing import Dict, Tuple
from urllib.error import URLError
from urllib.parse import urljoin, urlparse
from urllib.request import urlopen

import PIL.Image
import PIL.ImageGrab
import click
import iso8601
import psutil
import requests
from bs4 import BeautifulSoup
from cssutils import parseStyle

THIS_DIR = abspath(dirname(__file__))
PUBLIC_DIR = normpath(join(THIS_DIR, 'public'))
BASE_DIR = normpath(join(THIS_DIR, 'emptysquare'))
CONTENT_DIR = join(BASE_DIR, 'content')
STATIC_DIR = join(BASE_DIR, 'static')
LOCAL_BLOG_URL = 'http://localhost:1313/blog'

FULL_WIDTH = 2400
THUMB_WIDTH = 240
MAX_KB = 500


def get_image_dims(fpath: str) -> Tuple[int, int]:
    img = PIL.Image.open(fpath)
    return img.size


def computed_height(width, actual_width, actual_height):
    return int(float(actual_height) * (float(width) / float(actual_width)))


def get_quality(source_filename):
    ext = source_filename.rsplit('.', 1)[-1].lower()
    if ext.lower() == 'png':
        return 75
    return 85


def img_size_to(source_img, dst, width, suffix=''):
    root, ext = splitext(source_img)
    thumbnail_filename = '%s%s%s' % (basename(root), suffix, ext)
    target_img = join(dst, thumbnail_filename)
    if exists(target_img):
        os.remove(target_img)

    w, h = get_image_dims(source_img)
    if w <= width:
        # Don't resize.
        shutil.copy2(source_img, target_img)
    else:
        height = computed_height(width, w, h)
        cmdline = ['magick', source_img,
                   '-resize', '%dx%d' % (width, height),
                   '-auto-orient',
                   '-quality', str(get_quality(source_img)),
                   target_img]

        subprocess.check_call(cmdline)

    return thumbnail_filename


def read(path):
    with open(path, 'r') as f:
        return f.read()


def write(path, contents):
    with open(path, 'w') as f:
        f.write(contents)


@click.group()
def cli():
    """emptysqua.re blog utility."""
    pass


def is_image(filename):
    ext = splitext(filename)[-1]
    return ext.lower() in ('.png', '.jpg', '.jpeg', '.svg')


def is_thumb(filename):
    return re.match(r'.*?@\d+\.(png|jpg|jpeg)', filename, re.IGNORECASE)


def localpath(ctx, param, where):
    if where:
        return normpath(expanduser(where))


def wherepath(ctx, param, where):
    if not where:
        return

    _, ext = splitext(where)
    if ext:
        raise click.BadParameter("specify location without extension")

    return localpath(ctx, param, join(CONTENT_DIR, where))


def process_source_md(source, where):
    """Extract contents and images from a source Markdown file.

    If you ran 'blog draft foo.md', foo.md might have been exported from a Google doc
    with embedded images. Extract them and fix up the Markdown.
    """
    with open(source, 'r') as f:
        content = f.read()

    tmp_dir = tempfile.TemporaryDirectory()

    # Promote headers so the highest header level becomes H1.
    header_levels = [len(m) for m in re.findall(r"^(#+)", content, flags=re.MULTILINE)]
    if header_levels:
        min_level = min(header_levels)
        shift = max(min_level - 1, 0)
        if shift > 0:
            def promote(match):
                new_hashes = "#" * max(len(match.group(1)) - shift, 1)
                return f"{new_hashes}"

            content = re.sub(r"^(#+)", promote, content, flags=re.MULTILINE)

    # Extract base64 images.
    image_pattern = re.compile(r"\[([^\]]+)\]:\s*<data:image/png;base64,([^>]+)>")
    image_map = {}
    for match in image_pattern.finditer(content):
        label, b64data = match.groups()
        image_filename = f"{label}.png"
        image_path = f"{tmp_dir.name}/{image_filename}"
        with open(image_path, "wb") as img_file:
            img_file.write(base64.b64decode(b64data))

        image_map[label] = image_path

    # Replace image references in content, resize images and copy to media dir.
    for label, image_path in image_map.items():
        content = content.replace(f"![][{label}]",
                                  f'{{% pic src="{label}.png" alt="" / %}}')
        os.makedirs(where, exist_ok=True)
        try:
            w, h = get_image_dims(image_path)
            if w < FULL_WIDTH:
                print(f"Warning: {image_path} is only {w} x {h} px")
            img_size_to(image_path, where, FULL_WIDTH)
        except Exception as e:
            print(f"Skipping resize of {label}.png: {e}")
            shutil.copy(image_path, where)

    return content


@cli.command('draft')
@click.argument('where', type=click.Path(), callback=wherepath)
@click.argument('source', type=click.Path(), callback=localpath, required=False)
def blog_draft(where, source):
    is_gallery = False
    images_front_matter = ""
    images_markdown = ""
    contents = ""
    image_filenames = []
    fpath = where + ".md"
    if exists(fpath):
        raise click.BadParameter("%s already exists!" % fpath)

    if source:
        source = normpath(expanduser(source))
        if isdir(source):
            is_gallery = True
            image_filenames = [join(source, filename)
                               for filename in os.listdir(source)
                               if is_image(filename)]
        elif isfile(source):
            if is_image(source):
                image_filenames = [source]
            elif splitext(source)[-1] == '.md':
                contents = process_source_md(source, where)
            else:
                raise click.BadParameter("Unrecognized source type: %s" % source)
        else:
            raise click.FileError('"%s" does not exist!' % source)

        # Copy images to media directory for this post.
        if image_filenames:
            os.makedirs(where, exist_ok=True)
            for filename in image_filenames:
                print(filename)
                img_size_to(filename, where, FULL_WIDTH)

        if is_gallery:
            # Use "gallery" shortcode, in themes/hugo_theme_emptysquare/shortcodes/.
            images_front_matter = f'''
thumbnail = "{basename(min(image_filenames))}"'''
            plural = "s" if len(image_filenames) > 1 else ""
            # Quad {{{{ renders as {{.
            images_markdown = f"""{{{{< gallery path="{basename(where)}" >}}}}

<span style="color: gray">Image{plural} &copy; A. Jesse Jiryu Davis</span>
    """

    write(fpath, f"""+++
type = "post"
title = ""
description = ""
category = []
tag = []
draft = true
enable_lightbox = true{images_front_matter}
+++

{contents}
{images_markdown}
""")

    print(fpath)
    subprocess.call(['pycharm', fpath])


@cli.command('mv')
@click.option('--no-redirect')
@click.argument('from_name', metavar='from', type=click.Path(),
                callback=wherepath)
@click.argument('to_name', metavar='to', type=click.Path(), callback=localpath)
def blog_move(no_redirect, from_name, to_name):
    from_fpath = from_name + '.md'
    if not exists(from_fpath):
        raise click.FileError(from_fpath)

    if exists(to_name):
        raise click.BadParameter("%s already exists!" % to_name)

    to_fpath = to_name + '.md'
    if exists(to_fpath):
        raise click.BadParameter("%s already exists!" % to_fpath)

    os.rename(from_fpath, to_fpath)
    if isdir(from_name):
        shutil.copytree(from_name, to_name)

    if not no_redirect:
        redirects_path = normpath(join(STATIC_DIR, '_redirects'))

        redirects = read(redirects_path)

        from_path = '/blog/' + basename(from_name)
        to_path = '/blog/' + basename(to_name)
        if not re.search(r'^' + from_path, redirects):
            write(redirects_path, redirects.strip() + """
{:<35}{}
""".format(from_path, to_path))


def parse_post(content):
    state = "init"
    front_matter_lines = []
    content_lines = []
    for line in content.split('\n'):
        if line.strip() == '+++':
            if state == "init":
                state = "front matter"
            else:
                state = "content"

        elif state == "front matter":
            front_matter_lines.append(line.strip())

        else:
            content_lines.append(line)

    parsed = {}
    for l in front_matter_lines:
        key, value = l.split('=', 1)
        value = value.strip()
        if value == 'true':
            value = True
        elif value == 'false':
            value = False

        try:
            value = iso8601.parse_date(value)
        except iso8601.iso8601.ParseError:
            try:
                value = eval(str(value))
            except:
                pass

        parsed[key.strip()] = value

    return parsed, "\n".join(content_lines)


def unparse(post, contents):
    def to_str(value):
        if isinstance(value, datetime.datetime):
            return value.isoformat()
        else:
            return json.dumps(value)

    return """+++
%s
+++

%s
""" % (
        "\n".join(
            "%s = %s" % (k, to_str(v)) for k, v in sorted(post.items())),
        contents.strip())


def _gen_thumbnail(where, post, dirpath):
    images = [fname for fname in os.listdir(dirpath)
              if is_image(fname) and not is_thumb(fname)]

    thumb_file = None
    if len(images) > 1:
        # Require author to choose one image as the thumbnail.
        if not post.get('thumbnail'):
            raise click.BadParameter('"%s" no thumbnail!' % where)

        thumb_file = join(dirpath, post['thumbnail'])
    elif len(images) == 1:
        thumb_file = join(dirpath, images[0])
        post['thumbnail'] = images[0]

    if thumb_file:
        if not isfile(thumb_file):
            raise click.BadParameter('thumbnail "%s" not found!'
                                     % post['thumbnail'])

        thumb_name, thumb_ext = os.path.splitext(thumb_file)
        thumb_base = basename(thumb_name)
        if thumb_ext == ".svg":
            # Generated by _pngs_from_svgs and _compress_images.
            for ext in (".png", ".jpg"):
                thumb_file = thumb_name + ext
                if isfile(thumb_file):
                    post["thumbnail"] = thumb_base + ext
                    break
            else:
                raise click.BadParameter(
                    'thumbnail "%s" not converted from SVG' % post['thumbnail'])
        print(img_size_to(thumb_file, dirpath, THUMB_WIDTH,
                          suffix='@%d' % THUMB_WIDTH))


def _exterminate_ds_store(where):
    """Destroy .DS_Store files."""
    try:
        os.remove(os.path.join(where, ".DS_Store"))
    except FileNotFoundError:
        pass


def _check_unused_images(where, content):
    """Verify all images in directory are referenced in content."""
    if "{{< gallery" in content:
        return  # The gallery shortcode uses all images.

    image_files = [f for f in os.listdir(where) if is_image(f) and not is_thumb(f)]
    # Check each image appears as a word in content.
    for img in image_files:
        name, ext = os.path.splitext(img)
        if ext.lower() in (".png", ".jpg") and f"{name}.svg" in image_files:
            # Generated for RSS by _pngs_from_svgs, need not be in content.
            continue
        if ext.lower() == ".svg" and name.startswith("formula-"):
            # Generated for RSS by _pngs_from_math.
            continue
        if not re.search(r'\b' + re.escape(img) + r'\b', content):
            raise click.BadParameter(
                f"Image {img} is not used")


def _svgs_from_math(where, content):
    def _one_formula(match):
        formula = match.group(1).strip()
        outname = f"formula-{hashlib.sha256(formula.encode('utf-8')).hexdigest()}.svg"
        outpath = os.path.join(where, outname)
        if os.path.exists(outpath):
            return

        print(outname)
        with open(outpath, "w") as f:
            MAX_RETRIES = 3
            for i in range(MAX_RETRIES):
                try:
                    output = subprocess.check_output(
                        ["node", "tex2svg.mjs", formula],
                        cwd=THIS_DIR).decode("utf-8")
                    assert "data-mjx-error" not in output, output
                except Exception:
                    if i == MAX_RETRIES - 1:
                        raise
                    print(f"Failed to convert {formula}, retrying...")
                    time.sleep(i)
            f.write(output)

    for pattern in [r'\$\$(.*?)\$\$', r'\\\((.*?)\\\)']:
        for match in re.finditer(pattern, content, re.DOTALL):
            _one_formula(match)


def _pngs_from_svgs(where):
    for fname in os.listdir(where):
        name, ext = os.path.splitext(fname)
        if not ext.lower() == '.svg':
            continue

        outname = f"{name}.png"
        dst = os.path.join(where, outname)
        if os.path.exists(dst):
            continue

        print(f'Converting {fname} -> {outname}')
        # svgexport is the only thing I've found that works with Excalidraw SVGs'
        # embedded fonts. _compress_images may further process this image.
        MAX_RETRIES = 3
        for i in range(MAX_RETRIES):
            try:
                subprocess.check_call(
                    ["npx", "svgexport", os.path.join(where, fname), dst])
            except Exception:
                if i == MAX_RETRIES - 1:
                    raise
                print(f"Failed to convert {fname}, retrying...")
                time.sleep(i)


def _move_to_trash(file_path):
    subprocess.check_call([
        'osascript', '-e',
        f'tell application "Finder" to delete POSIX file "{file_path}"'],
        stdout=subprocess.DEVNULL)


def _compress_images(where) -> Dict[str, str]:
    """Returns dict: original_image_fname -> compressed_image_fname."""
    compressed_images = {}
    for fname in os.listdir(where):
        name, ext = os.path.splitext(fname)
        ext = ext.lower()
        if ext not in (".png", ".jpg", ".jpeg"):
            continue
        fpath = os.path.join(where, fname)
        image = PIL.Image.open(fpath)
        format = 'PNG' if ext == '.png' else 'JPEG'

        if image.width > FULL_WIDTH:
            ratio = FULL_WIDTH / float(image.width)
            new_height = int(float(image.height) * ratio)
            image = image.resize((FULL_WIDTH, new_height), PIL.Image.LANCZOS)
            image.save(fpath, format=format)

        size_kb = os.stat(fpath).st_size // 1024
        if size_kb <= MAX_KB:
            continue

        # Compress the image until it's at most MAX_KB.
        if ext == '.png':
            # Convert PNG to JPEG.
            new_fname = f"{name}.jpg"
            new_fpath = os.path.join(where, new_fname)
            new_format = 'JPEG'
            image = image.convert("RGB")  # JPEG doesn't support transparency.
        else:
            new_fname = fname
            new_fpath = fpath
            new_format = format

        # Iteratively compress until size is acceptable.
        quality = 70
        while True:
            buffer = io.BytesIO()
            image.save(buffer, format=new_format, optimize=True, quality=quality)
            size_kb = len(buffer.getvalue()) // 1024
            quality -= 10
            if size_kb <= MAX_KB or quality <= 10:
                break

        print(f"Compressed {fname} -> {new_fname}, trashing original")
        _move_to_trash(fpath)
        with open(new_fpath, 'wb') as f:
            f.write(buffer.getvalue())

        compressed_images[fname] = new_fname

    return compressed_images


@cli.command('replace-quotes')
@click.argument('where', type=click.Path(), callback=wherepath)
def blog_replace_quotes(where):
    fpath = where + ".md"
    if not exists(fpath):
        raise click.FileError(fpath)

    post, contents = parse_post(read(fpath))
    for smart, dumb in [("\u2018", "'"), ("\u2019", "'"),
                        ("\u201c", '"'), ("\u201d", '"')]:
        contents = contents.replace(smart, dumb)

    write(fpath, unparse(post, contents))


@cli.command('publish')
@click.argument('where', type=click.Path(), callback=wherepath)
@click.pass_context
def blog_publish(ctx, where):
    fpath = where + ".md"
    if not exists(fpath):
        raise click.FileError(fpath)

    post, contents = parse_post(read(fpath))

    if "JESSE TODO" in contents:
        raise click.BadParameter('"%s" contains "JESSE TODO"' % where)

    if not post.get('description'):
        raise click.BadParameter('"%s" missing description!' % where)

    if not post.get('description').endswith(('?', '.', '!')):
        raise click.BadParameter(
            '"%s" description does not end with punctuation' % where)

    description_len = len(post['description'])
    if description_len > 150:
        raise click.BadParameter(
            '"%s" description is too long: %d characters, aim for 150' %
            (where, description_len))

    if not post.get('title'):
        raise click.BadParameter('"%s" missing title!' % where)

    if post.get('title').endswith('.'):
        raise click.BadParameter('"%s" title should not end in period!' % where)

    if not post.get('category') and post['type'] == 'post':
        raise click.BadParameter('"%s" no categories!' % where)

    for c in post['category']:
        if not (len(c) and c[0].upper() == c[0]):
            raise click.BadParameter('category "%s" should be title-cased' % c)

    if isdir(where):
        _exterminate_ds_store(where)
        _check_unused_images(where, contents)
        _svgs_from_math(where, contents)
        _pngs_from_svgs(where)  # Should come after _svgs_from_math.
        img_replacements = _compress_images(where)
        for original, compressed in img_replacements.items():
            # Replace img refs like {{% pic src="foo.png" caption="..." alt="..." / %}}
            # Works for handwritten <img> tags too.
            contents = contents.replace(f'src="{original}"', f'src="{compressed}"')
        if post.get('thumbnail') in img_replacements:
            post['thumbnail'] = img_replacements[post['thumbnail']]

        # Save progress in case _gen_thumbnail throws an exception.
        write(fpath, unparse(post, contents))
        _gen_thumbnail(where, post, where)

    if post.get('draft', False):
        post['draft'] = False
        post['date'] = datetime.datetime.now(datetime.timezone.utc).isoformat()
    else:
        # Already published.
        assert post['date']

    write(fpath, unparse(post, contents))
    print("Letting hugo reload")
    time.sleep(5)
    ctx.invoke(server, action='start')
    _check(LOCAL_BLOG_URL)


@cli.command('thumbnail')
@click.argument('where', type=click.Path(), callback=wherepath)
def thumbnail(where):
    fpath = where + ".md"
    if not exists(fpath):
        raise click.FileError(fpath)

    post, contents = parse_post(read(fpath))

    if not isdir(where):
        raise click.FileError(where)

    _gen_thumbnail(where, post, where)
    write(fpath, unparse(post, contents))


@cli.command('media')
@click.argument('where', type=click.Path(), callback=wherepath)
def media(where):
    fpath = where + ".md"
    if not exists(fpath):
        raise click.FileError(fpath)

    if not isdir(where):
        os.mkdir(where)

    subprocess.check_call(['open', where])


def _add_image(where, image):
    fpath = where + ".md"
    if not exists(fpath):
        raise click.FileError(fpath)

    if not isdir(where):
        os.mkdir(where)

    shutil.copy(image, where)
    if not image.endswith(".svg"):
        img_size_to(image, where, FULL_WIDTH)

    # Copy the image Markdown to the clipboard so user can paste it wherever.
    image_filename = split(image)[1]
    md = f'{{{{% pic src="{image_filename}" alt="" / %}}}}'
    process = subprocess.Popen('pbcopy', env={'LANG': 'en_US.UTF-8'},
                               stdin=subprocess.PIPE)
    process.communicate(md.encode('utf-8'))
    print('The Markdown code for the image is in your clipboard')


@cli.command('add-image')
@click.argument('where', type=click.Path(), callback=wherepath)
@click.argument('image', type=click.Path(), callback=localpath)
def add_image(where, image):
    _add_image(where, image)


@cli.command('paste-image')
@click.argument('where', type=click.Path(), callback=wherepath)
@click.argument('name')
def paste_image(where, name):
    if not name:
        raise click.BadParameter("empty image filename")

    img = PIL.ImageGrab.grabclipboard()
    assert img
    with tempfile.TemporaryDirectory() as tmpdir:
        image_path = os.path.join(tmpdir, f'{name}.png')
        img.save(image_path, format='PNG')
        _add_image(where, image_path)

    subprocess.check_call(['osascript', '-e', '''
tell application "PyCharm" to activate

tell application "System Events"
    tell application process "PyCharm"
        tell menu bar 1
            tell menu bar item "Edit"
                tell menu "Edit"
                    tell menu item "Paste"
                        tell menu "Paste"
                            click menu item "Paste"
                        end tell
                    end tell
                end tell
            end tell
        end tell
    end tell
end tell'''])


@cli.command('pngs-from-svgs')
@click.argument('where', type=click.Path(), callback=wherepath)
def pngs_from_svgs(where):
    if not isdir(where):
        raise click.FileError(where)

    _pngs_from_svgs(where)


def _check(url):
    print(f"Checking site, crawling from {url}")
    seen_pages = set()
    seen_images = set()
    ok = True
    session = requests.Session()
    session.mount('http://', requests.adapters.HTTPAdapter(max_retries=3))
    session.mount('https://', requests.adapters.HTTPAdapter(max_retries=3))

    if 'localhost' in url or '127.0.0.1' in url:
        redirects = {
            src.strip(): dst.strip() for src, dst in [
                line.split(None, 1) for line in
                open(os.path.join(STATIC_DIR, "_redirects")).readlines()
            ]
        }
    else:
        redirects = {}

    def check_image(page_url, src):
        nonlocal ok
        img_url = urljoin(page_url, src)
        # Never check external images: too unreliable.
        if not img_url.startswith(url):
            return

        if img_url in seen_images:
            return
        seen_images.add(img_url)
        with session.head(img_url) as response:
            if response.status_code == 404:
                print(f"404 {img_url} from {page_url}")
                ok = False

    def check_html(page_url, soup):
        for img in soup.find_all('img'):
            check_image(page_url, img['src'])
        for source in soup.find_all('source'):
            if source.get('src'):
                check_image(page_url, source['src'])
            if source.get('srcset'):
                for src in source.get('srcset', '').split(','):
                    check_image(page_url, src.split()[0])

    def check_url(from_url, page_url):
        nonlocal ok
        page_url = redirects.get(urlparse(page_url).path, page_url)
        if page_url in seen_pages or not page_url.startswith(url):
            return
        seen_pages.add(page_url)
        with session.get(page_url) as response:
            if response.status_code == 404:
                print(f"404 {page_url} from {from_url}")
                ok = False
            soup = BeautifulSoup(response.text, 'html.parser')
            check_html(response.url, soup)  # Use redirected URL, if any

        # Crawl links
        for a in soup.find_all('a', href=True):
            check_url(
                page_url,
                urljoin(page_url, a['href'].split('#', -1)[0]))  # Ignore fragment.

    # Check RSS feed.
    rss_url = url.rstrip('/') + '/index.xml'
    seen_pages.add(rss_url)
    with session.get(rss_url) as response:
        soup = BeautifulSoup(response.text, 'xml')
    for item in soup.find_all('item'):
        desc = item.find('description')
        desc_soup = BeautifulSoup(desc.text, 'html.parser')
        check_html(rss_url, desc_soup)
        for img in desc_soup.find_all('img'):
            styles = parseStyle(img.get('style', ''))
            # Check with or without a space after colon.
            if not styles.maxWidth and not styles.width and styles.display != "inline":
                img_base = img['src'].split('/')[-1]
                print(
                    f"Image {img_base} in RSS for '{item.title.text}' has no width")
                ok = False

    # Check root page.
    check_url('NULL', url)

    if not ok:
        raise click.ClickException(f"Check failed")

    print(f"Checked {len(seen_pages)} pages and {len(seen_images)} images")


@cli.command('check')
@click.argument('url', default=LOCAL_BLOG_URL)
def check(url):
    _check(url)


def _parsed_posts():
    for name in glob.glob(CONTENT_DIR + '/*.md'):
        post, contents = parse_post(read(join(CONTENT_DIR, name)))
        yield post, contents


def counts(field):
    counter = Counter()
    for post, _ in _parsed_posts():
        value = post.get(field, [])
        if value:
            counter.update(value)

    sorted_cnts = sorted([(value, cnt) for value, cnt in counter.items()],
                         key=lambda pair: -pair[1])

    print('\n'.join('{:<23}{:>3}'.format(value, cnt)
                    for value, cnt in sorted_cnts))


@cli.command('tag')
@click.argument('tag')
def tag(tag):
    for post, _ in _parsed_posts():
        if tag in post.get('tag', []):
            print(post['title'])


@cli.command('tags')
def tags():
    counts('tag')


@cli.command('categories')
def categories():
    counts('category')


@cli.command('drafts')
def categories():
    for post, _ in _parsed_posts():
        if post.get('draft'):
            print(post['title'])


SUPERVISOR_CONF = 'supervisord.conf'
BINDIR = os.path.dirname(sys.executable)


def start_supervisord():
    subprocess.check_output(['%s/supervisord' % BINDIR, '-c', SUPERVISOR_CONF],
                            cwd=BASE_DIR)


def supervisorctl(command):
    subprocess.check_call(
        ['%s/supervisorctl' % BINDIR, '-c', SUPERVISOR_CONF] + command,
        cwd=BASE_DIR)


@cli.command('server')
@click.argument('action', type=click.Choice(['start', 'stop', 'restart']))
def server(action):
    # Assume Python and Supervisor are both in the same virtualenv.
    if not os.path.exists('supervisord.pid'):
        start_supervisord()
    else:
        # Check that supervisord.pid represents a running process.
        pid = int(open('supervisord.pid').read().strip())
        try:
            psutil.Process(pid)
        except psutil.NoSuchProcess:
            start_supervisord()

    supervisorctl([action, 'all'])
    if action in ('start', 'restart'):
        # Wait for startup.
        for _ in range(10):
            try:
                urlopen('http://localhost:1313/blog/').read()
            except (URLError, socket.error) as exc:
                print(exc)
                supervisorctl(['tail', 'hugo'])
                time.sleep(1)

        # Sometimes needs another second.
        time.sleep(1)
    elif action == 'stop':
        supervisorctl(['shutdown'])


@cli.command('preview')
@click.argument('where', type=click.Path(), callback=wherepath)
@click.pass_context
def preview(ctx, where):
    fpath = where + ".md"
    if not exists(fpath):
        raise click.FileError(fpath)

    ctx.invoke(server, action='start')
    path = where.split('content/')[-1]
    webbrowser.open_new_tab('http://localhost:1313/blog/%s' % path)


@cli.command('build')
def build():
    if os.path.exists('supervisord.pid'):
        os.kill(int(open('supervisord.pid').read().strip()), signal.SIGTERM)

    subprocess.check_call(['hugo', '--logLevel', 'info', 'build', '-d',
                           join(PUBLIC_DIR, 'blog')], cwd=BASE_DIR)

    shutil.copytree(STATIC_DIR, PUBLIC_DIR, dirs_exist_ok=True)


@cli.command('deploy')
@click.pass_context
def deploy(ctx):
    ctx.invoke(build)
    subprocess.check_call(
        ['netlify', 'deploy', '-s', 'emptysquare', '-p', 'public'])


cli()
